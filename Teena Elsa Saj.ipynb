{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is Dimensionality Reduction in Machine Learning?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Large amounts of memory and computational power are required for handling\n",
    "huge data. Sometimes, there can be features which are highly correlated and thus redundant.\n",
    "Reducing the number of features costs some accuracy and it makes large datasets\n",
    "simpler,easy to explore and analyse.\n",
    "There can be thousands or millions of input variables in certain datasets.\n",
    "This is where Dimensionaly reduction comes in and contribute to a simpler and general machine \n",
    "learning model with the dimensionality-reduced input data.\n",
    "It refers to techniques for reducing the number of input variables in\n",
    "the training data. If the technique is applied for training data, it should also be done for test,\n",
    "validation and any other dataset used in the prediction.\n",
    "\n",
    "There are two components involved in Dimensionality Reduction.\n",
    "These are : Feature Selection and Feature Extraction.\n",
    "Feature selection refers to obtaining a subset of the original variables in the high-dimension data.\n",
    "This subset is later used in the modeling part.\n",
    "Feature extraction refers to the reduction in the dimension of the dataset.\n",
    "\n",
    "Principal Component Analysis is one of the most common methods of Dimensionality Reduction \n",
    "which is done by transforming the variables to a new set of variables that are orthogonal such that\n",
    "the there is no loss of important information. The output of PCA are the Principal Components, the number\n",
    "of which is less than that number of original variables.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How can you handle duplicate values in a dataset for a variable in Python using pandas?\n",
    "### Suppose, you are given the following dataset:\n",
    "### df = pd.read_csv('file.csv')\n",
    "### This dataset has many duplicate values. You need to identify them and also remove them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Inorder to check whether there are duplicates present in the dataset, the following function can be used. \n",
    "#This is to check whether an entire row is duplicated with the same values in each column over the dataset.\n",
    "#This will return True/False according to the duplications.\n",
    "\n",
    "df.duplicated()\n",
    "\n",
    "\n",
    "#Inorder to check whether there are duplicates in a specific column, we can use the following function. \n",
    "#This will also return True/False according to the duplication.\n",
    "\n",
    "df.duplicated('COL1')\n",
    "\n",
    "#For getting rid of the duplicates in the dataset, the following function is used.\n",
    "\n",
    "df.drop_duplicates()\n",
    "\n",
    "#For removing duplicates from a particular column in the dataset, we can use\n",
    "\n",
    "df.drop_duplicates('COL1')\n",
    "\n",
    "#Along with this,it is also possible to indicate whether we want to keep the first argument (keep=’first’), the last argument (keep=’last’) \n",
    "#from the duplicates or drop all the duplicates altogether (keep=False).\n",
    "\n",
    "df.drop_duplicates('COL1',keep='first')\n",
    "df.drop_duplicates('COL2',keep='last')\n",
    "df.drop_duplicates('COL3',keep=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
